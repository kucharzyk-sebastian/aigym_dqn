{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# <center>Agent DQN doszkalany ewolucyjnie</center>\n",
    "<center><img src=\"https://media.giphy.com/media/dyde6O8yn4oRh7R1Vk/source.gif\" width=\"460\" height=\"280\" /></center>\n",
    "\n",
    "*<center>Wykonali</center>*\n",
    "*<center>Jakub Gros, Sebastian Kucharzyk</center>*\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Cel i wstępna analiza problemu\n",
    "<p style='text-align: justify;'>\n",
    "Jako cel obraliśmy sobie stworzenie maszynowego odpowiednika człowieka grającego w grę \n",
    "komputerową(tzw. agenta), który ucząc się na własnych błędach, będzie osiągał w niej coraz to lepsze \n",
    "rezultaty. Do tego celu nadaje się m.in. paradygmat procesu uczenia nazywany uczeniem ze wzmocnieniem,\n",
    "polegający na umieszczeniu uczącego się agenta w nieznanym mu dotąd środowisku i pozwoleniu na \n",
    "wykonywanie dowolnych interakcji z otoczeniem. Agent w trakcie eksploracji doświadcza wielu różnych \n",
    "sytuacji zwanych stanami. Znajdując się w danym stanie wybiera, którą z obecnie możliwych akcji \n",
    "wykona, za co  finalnie otrzymuje pewną nagrodę lub karę. Wszystkie informacje na temat ruchów i \n",
    "nagród przechowuje w pamięci, aby nastepnie na ich podstawie móc oceniać, jaka akcja da mu \n",
    "największą nagrodę.\n",
    "</p>\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<p style='text-align: justify;'>\n",
    "Pozornie wydawałoby się, że rozwiązanie to nadaje się niemal idealnie do sytuacji \n",
    "wymagających, aby agent sam zebrał dane, na których następnie będzie się uczył, ale niestety posiada ono \n",
    "jedną znaczącą wadę - wraz z upływem czasu ilość danych w pamięci agenta rośnie, co z kolei powoduje \n",
    "spowolnienie podejmowania decyzji, a finalnie może nawet doprowadzić do zapełnienia pamięci \n",
    "fizycznej urządzenia.\n",
    "</p>\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<p style='text-align: justify;'>\n",
    "Aby uniknąć problemów związanych z nadmiarem danych, zdecydowaliśmny się na wykorzystanie innego paradygmatu, \n",
    "który pozwala zgeneralizować zbiór danych zamiast nieskończenie go poszerzać i przeszukiwać. Dokładniej \n",
    "rzecz ujmując, wybór padł na zastosowanie głębokiego Q-learningu, czyli połączenia uczenia \n",
    "ze wzmocnieniem z uczeniem głębokim. Polega on na zastąpieniu nieograniczonej pamięci agenta siecią neuronową \n",
    "wspomaganą relatywnie małym buforem pamiętającym N ostatnich wyborów. Ponadto po każdej akcji podjętej przez agenta\n",
    "z buforu wybierany jest mały fragment danych, na których następnie sieć jest dotrenowywana.\n",
    "Wykonuje się to za pomocą Q-wartości, czyli pewnej funkcji  <b>Q(S, A)</b> szacującej jak bardzo opłaca się \n",
    "podjąć akcję A będąc w stanie S. Cały powyższy proces prowadzi do stworzenia modelu Deep Q-Network(DQN).\n",
    "</p>\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<p style='text-align: justify;'>\n",
    "Tutaj zakres projektu mógłby się zakończyć, ale nie chcieliśmy się ograniczać jedynie do głębokiego Q-learningu, \n",
    "więc postanowiliśmy znaleźć zastosowanie dla innego zagadnienia z zakresu stucznej inteligencji - algorytmów \n",
    "ewolucyjnych. Patrząc na sposób działania modelu DQN można zauważyć trzy obszary, które potencjalnie nadają się \n",
    "do ulepszenia ewolucyjnego:\n",
    "</p>\n",
    "\n",
    "1. Kształt sieci neuronowej\n",
    "2. Wagi połączeń międzyneuronowych\n",
    "3. Dane przechowywane w pamięci agentów\n",
    "\n",
    "<p style='text-align: justify;'>\n",
    "Po dokładnym przeanalizowaniu powyższych możliwości zdecydowaliśmy się odrzucić opcje numer 1 oraz 3. \n",
    "O wyeliminowaniu manipulacji kształtem sieci neuronowej zadecydował fakt, że wolimy skupić się na\n",
    "stworzeniu jednego wariantu sieci i jego dogłębnej analizie niż na pobieżnym tworzeniu wielu modeli tylko \n",
    "po to, żeby różniły się budową. Natomiast jeśli chodzi o opcję trzecią, to jej odrzucenie wynika z \n",
    "natury DQN, której agent przechowuje w pamięci jedynie mały  fragment z całego zbioru danych, \n",
    "na którym był uczony. W takim wypadku używanie go jako podstawy do dalszego ulepszania najprawdopodobniej nie \n",
    "prowadziłoby do uzyskania wymiernych korzyści. W ten sposób stwierdziliśmy, że najciekawszym i (oby) \n",
    "najefektywniejszym podejściem będzie zastosowanie algorytmu genetycznego operującego na wagach połączeń \n",
    "międzyneuronowych.\n",
    "</p>\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Ocena jakości modelu\n",
    "<p style='text-align: justify;'>\n",
    "Aby rzetelnie ocenić jakość modelu, należy najpierw upewnić się, że wyniki przez niego osiągane są stabilne oraz \n",
    "wiarygodne. Mianem stabilnych określamy je wtedy, gdy w trakcie rozgrywania kolejnych gier przyjmują one zbliżone \n",
    "do siebie wartości. Aby osiągnąć taki rezultat, wymagane jest trenowanie modelu na odpowiedniej \n",
    "(nie za małej) liczbie gier. Metodą prób i błędów określiliśmy, że dla różnych modeli w naszym środowisku treningowym\n",
    "liczba ta oscyluje przeważnie w granicach 200.\n",
    "</p>\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<p style='text-align: justify;'>\n",
    "Z kolei jeśli chodzi o wiarygodność, to uzyskiwane przez dany model rezultaty uznajemy za wiarygodne wtedy, gdy \n",
    "nie są one wypaczone przez losowe warunki początkowe. Istnieją dwa różne podejścia pomagające w zapewnieniu \n",
    "wiarygodności wyników:\n",
    "</p>\n",
    "\n",
    "1. Trenowanie każdego modeli w identycznych warunków początkowych\n",
    "2. Zastosowanie pewnej funkcji oceny, np. wyciągnięcia średniej z kilku różnych prób wytrenowania tego samego modelu.\n",
    "\n",
    "<p style='text-align: justify;'>\n",
    "Ze względu na to, że ideą głębokiego Q-learningu jest eksploracja środowiska w sposób losowy, nasz wybór musiał \n",
    "paść na opcję numer 2.\n",
    "</p>\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<p style='text-align: justify;'>\n",
    "Zważając na powyższe rozważania zdecydowaliśmy, że każdy z naszych modeli będzie trenowany dokładnie cztery \n",
    "razy po dwieście gier. Z rezultatów osiąganych we wszystkich czterech podejściach wyciągniemy średnią, a \n",
    "następnie porównamy ją z innymi modelami."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Etapy działania\n",
    "Podsumowując przeprowadzoną powyżej analizę, zdecydowaliśmy się podzielić realizację projektu na następujące \n",
    "fazy:\n",
    "1. Implementacja i gromadzenie rezultatów naiwnego agenta, który podejmuje decyzje w sposób losowy. Posłuży on \n",
    "jako wyznacznik do porównywania innych modeli.\n",
    "2. Implementacja i gromadzenie rezultatów agenta wykorzystującego prostą sieć neuronową.\n",
    "3. Modyfikacja implementacji agenta oraz parametrów sieci neuronowej w celu poprawy osiąganych rezultatów.\n",
    "4. Wytrenowanie początkowej populacji agentów i zastosowanie algorytmu genetycznego do stworzenia osobnika z \n",
    "jak najlepiej dostosowanymi wagami międzyneuronowymi.\n",
    "5. Porównanie osiągniętych rezultatów i wyciągnięcie wniosków z doświadczenia.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Zastosowane technologie\n",
    "<p style='text-align: justify;'>\n",
    "Kod projektu napisaliśmy w języku Python w wersji 3.6. Sieć neuronowa oraz wszelkie struktury i metody\n",
    "z nią  związane pochodzą z wysokopoziomowego API Kerasa bazującego na bibliotece TensorFlow. Jeśli zaś \n",
    "chodzi o samo środowisko do trenowania agenta, wykorzystaliśmy zestaw narzędzi AI Gym, a dokładniej\n",
    "środowisko gry Cart Pole. Ponadto aby maksymalnie wykorzystać możliwości sprzętowe zdecydowaliśmy, że \n",
    "części kodu wymagające wykonywania sekwencyjnego będą uruchamiane z użyciem procesora, a fragmenty \n",
    "możliwe do zrównoleglenia obsłuży karta graficzna. \n",
    "</p>\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Dygresja na temat podjętych decyzji\n",
    "<p style='text-align: justify;'>\n",
    "Pierwszą wersję modelu stworzyliśmy z myślą o uniwersalności. Zasadniczo była ona zdolna do współpracy z \n",
    "większością środowisk dostępnych poprzez interfejs AI Gym. Dzięki temu zabiegowi byliśmy w stanie przeprowadzić \n",
    "serię prób pozwalających na wyłonienie najlepszego kandydata do dalszego ulepszania modelu. Testy zaczęliśmy od \n",
    "bardziej złożonych środowisk (BipedalWalker-v2) poprzez te średnio skomplikowane (LunarLander-v2) aż po \n",
    "najłatwiejsze (CartPole-v1). Niestety okazało się, że nasz sprzęt nie jest w stanie wytrenowaćsieci neuronowej \n",
    "dla żadnego z zaawansowanych środowisk w akceptowalnych ramach czasowych.\n",
    "</p>\n",
    "\n",
    "<p style='text-align: justify;'>\n",
    "Mówiąc konkretniej, trenowanie naszego modelu do stopnia, w którym jego wyniki są powtarzalne i pozwalają na \n",
    "wyciąganie sensownych wniosków, zajmuje około 10 minut w najprostszym środowisku (CartPole). Natomiast w drugim \n",
    "co do złożoności LunarLander czas ten jest niemal pięciokrotnie większy. Idąc dalej, po oszacowaniu, że do \n",
    "zakończenia projektu będziemy musieli trenować model w różnych konfiguracjach blisko 100 razy, liczba 75 godzin \n",
    "spędzonych na samym oczekiwaniu na wytrenowanie się sieci neuronowej dla LunarLandera byłaby zbyt duża. \n",
    "Na tej podstawie zdecydowaliśmy, że najlepszym rozwiązaniem będzie wykorzystanie środowiska Cart Pole.\n",
    "</p>\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Trenowanie i implementacja"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import random\n",
    "import gym\n",
    "import tensorflow as tf\n",
    "a = random.randint()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "NUM_OF_EPISODES = 200\n",
    "FRAMES_PER_EPISODE = 1000\n",
    "BATCH_SIZE = 32\n",
    "GAME_ID = 'CartPole-v1'\n",
    "CPU_ID = '/device:CPU:0'\n",
    "print(0)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Header"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Header"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Header"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### Header"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import numpy"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}